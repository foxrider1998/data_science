{"cells":[{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      gender   age  hypertension  heart_disease ever_married      work_type  \\\n","0       Male  67.0             0              1          Yes        Private   \n","1     Female  61.0             0              0          Yes  Self-employed   \n","2       Male  80.0             0              1          Yes        Private   \n","3     Female  49.0             0              0          Yes        Private   \n","4     Female  79.0             1              0          Yes  Self-employed   \n","...      ...   ...           ...            ...          ...            ...   \n","5105  Female  80.0             1              0          Yes        Private   \n","5106  Female  81.0             0              0          Yes  Self-employed   \n","5107  Female  35.0             0              0          Yes  Self-employed   \n","5108    Male  51.0             0              0          Yes        Private   \n","5109  Female  44.0             0              0          Yes       Govt_job   \n","\n","     Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n","0             Urban             228.69  36.6  formerly smoked       1  \n","1             Rural             202.21   NaN     never smoked       1  \n","2             Rural             105.92  32.5     never smoked       1  \n","3             Urban             171.23  34.4           smokes       1  \n","4             Rural             174.12  24.0     never smoked       1  \n","...             ...                ...   ...              ...     ...  \n","5105          Urban              83.75   NaN     never smoked       0  \n","5106          Urban             125.20  40.0     never smoked       0  \n","5107          Rural              82.99  30.6     never smoked       0  \n","5108          Rural             166.29  25.6  formerly smoked       0  \n","5109          Urban              85.28  26.2          Unknown       0  \n","\n","[5110 rows x 11 columns]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","diabetes_dataset = pd.read_csv('./healthcare-dataset-stroke-data.csv')\n","\n","df = pd.DataFrame(diabetes_dataset, columns = ['gender','age','hypertension','heart_disease','ever_married','work_type','Residence_type','avg_glucose_level','bmi','smoking_status','stroke'])\n","\n","print(df)\n"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      gender   age  hypertension  heart_disease  ever_married  work_type  \\\n","0        0.0  67.0             0              1             1        0.0   \n","1        1.0  61.0             0              0             1        1.0   \n","2        0.0  80.0             0              1             1        0.0   \n","3        1.0  49.0             0              0             1        0.0   \n","4        1.0  79.0             1              0             1        1.0   \n","...      ...   ...           ...            ...           ...        ...   \n","5105     1.0  80.0             1              0             1        0.0   \n","5106     1.0  81.0             0              0             1        1.0   \n","5107     1.0  35.0             0              0             1        1.0   \n","5108     0.0  51.0             0              0             1        0.0   \n","5109     1.0  44.0             0              0             1        2.0   \n","\n","      Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n","0                  1             228.69  36.6               1       1  \n","1                  0             202.21   NaN               0       1  \n","2                  0             105.92  32.5               0       1  \n","3                  1             171.23  34.4               2       1  \n","4                  0             174.12  24.0               0       1  \n","...              ...                ...   ...             ...     ...  \n","5105               1              83.75   NaN               0       0  \n","5106               1             125.20  40.0               0       0  \n","5107               0              82.99  30.6               0       0  \n","5108               0             166.29  25.6               1       0  \n","5109               1              85.28  26.2               3       0  \n","\n","[5110 rows x 11 columns]\n"]},{"ename":"ValueError","evalue":"Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [93], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m X_train, x_test, Y_train, Y_test\u001b[39m=\u001b[39m train_test_split(X, Y, test_size\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, stratify\u001b[39m=\u001b[39mY, random_state\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     62\u001b[0m classifier \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC (kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m classifier\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     64\u001b[0m X_train_prediction \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict (X_train)\n\u001b[1;32m     65\u001b[0m training_data_accuracy \u001b[39m=\u001b[39m accuracy_score(X_train_prediction, Y_train)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    174\u001b[0m         X,\n\u001b[1;32m    175\u001b[0m         y,\n\u001b[1;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    177\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    179\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    184\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    185\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    186\u001b[0m )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}],"source":["\n","\n","# df = pd.DataFrame(diabetes_dataset)\n","\n","\n","\n","def gender_to_numeric(x):\n","        if x=='Female': return 1\n","        if x=='Male':   return 0\n","\n","df['gender'] = df['gender'].apply(gender_to_numeric)\n","\n","\n","def ever_married_to_numeric(x):\n","        if x=='Yes': return 1\n","        if x=='No':   return 0\n","\n","df['ever_married'] = df['ever_married'].apply(ever_married_to_numeric)\n","\n","\n","def Residence_type_to_numeric(x):\n","        if x=='Urban': return 1\n","        if x=='Rural':   return 0\n","\n","df['Residence_type'] = df['Residence_type'].apply(Residence_type_to_numeric)\n","\n","\n","\n","def smoking_status_to_numeric(x):\n","        if x=='never smoked': return 0\n","        if x=='formerly smoked':   return 1\n","        if x=='smokes':   return 2\n","        if x=='Unknown':   return 3\n","\n","\n","df['smoking_status'] = df['smoking_status'].apply(smoking_status_to_numeric)\n","\n","def work_type_to_numeric(x):\n","        if x=='Private': return 0\n","        if x=='Self-employed':   return 1\n","        if x=='Govt_job':   return 2\n","        \n","\n","df['work_type'] = df['work_type'].apply(work_type_to_numeric)\n","\n","\n","print(df)\n","\n","X = df.drop (columns='stroke', axis=1)\n","Y = df['stroke']\n","\n","\n","scaler = StandardScaler ()\n","\n","scaler.fit(X)\n","standarized_data = scaler.transform(X)\n","\n","X = standarized_data\n","Y = diabetes_dataset['stroke']\n","\n","X_train, x_test, Y_train, Y_test= train_test_split(X, Y, test_size= 0.2, stratify=Y, random_state=2)\n","\n","\n","classifier = svm.SVC (kernel='linear')\n","classifier.fit(X_train, Y_train)\n","X_train_prediction = classifier.predict (X_train)\n","training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n","print('Akurasi data training adalah = ', training_data_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["          work_type  ever_married  gender  Residence_type  smoking_status\n","0           Private             1     0.0               1             1.0\n","1     Self-employed             1     1.0               0             0.0\n","2           Private             1     0.0               0             0.0\n","3           Private             1     1.0               1             2.0\n","4     Self-employed             1     1.0               0             0.0\n","...             ...           ...     ...             ...             ...\n","5105        Private             1     1.0               1             0.0\n","5106  Self-employed             1     1.0               1             0.0\n","5107  Self-employed             1     1.0               0             0.0\n","5108        Private             1     0.0               0             1.0\n","5109       Govt_job             1     1.0               1             NaN\n","\n","[5110 rows x 5 columns]\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0.63994726  0.84832379  0.14964075  0.90726993 -0.69289057  0.20401277\n","   0.46849198  1.4259954 ]]\n","[1]\n","Pasien terkena diabetes\n"]},{"name":"stderr","output_type":"stream","text":["/home/aris/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n","  warnings.warn(\n"]}],"source":["input_data = (6, 148, 72, 35, 0, 33.6, 0.627, 50)\n","input_data_as_numpy_array= np.array(input_data)\n","input_data_reshape = input_data_as_numpy_array.reshape(1, -1)\n","std_data = scaler.transform(input_data_reshape)\n","print(std_data)\n","prediction = classifier.predict(std_data)\n","print (prediction)\n","\n","if (prediction [0] == 0):\n","    print('Pasien tidak terkena diabetes')\n","else :\n","    print('Pasien terkena diabetes')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","\n","filename='diabetes_model.sav'\n","pickle.dump(classifier,open(filename,'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump(classifier,open(filename,'rb'))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
